{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e82d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b809b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# Assuming the trimmed sales data for February 2024 has already been generated\n",
    "# by the 'Generate Trimmed Sales Data for February 2024' immersive.\n",
    "TRIMMED_SALES_FILE_PATH = r'C:\\Users\\Pavan\\Downloads\\archive (1)\\trimmed_sales_feb_2024.csv'\n",
    "PRODUCTS_FILE_PATH = r'C:\\Users\\Pavan\\Downloads\\archive (1)\\products.csv'\n",
    "CATEGORIES_FILE_PATH = r'C:\\Users\\Pavan\\Downloads\\archive (1)\\categories.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aff0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 1: Loading Trimmed Sales Data and Auxiliary Files ---\")\n",
    "try:\n",
    "    trimmed_sales_df = pd.read_csv(TRIMMED_SALES_FILE_PATH)\n",
    "    products_df = pd.read_csv(PRODUCTS_FILE_PATH)\n",
    "    categories_df = pd.read_csv(CATEGORIES_FILE_PATH)\n",
    "    print(f\"Successfully loaded '{TRIMMED_SALES_FILE_PATH}', '{PRODUCTS_FILE_PATH}', and '{CATEGORIES_FILE_PATH}'.\")\n",
    "    print(f\"Trimmed sales data size: {len(trimmed_sales_df)} rows.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading file: {e}. Please ensure all necessary CSV files are in the correct location.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f093c96",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Ensure 'SalesDate' is datetime type for consistency, as it might become object after saving/loading CSV\n",
    "trimmed_sales_df['SalesDate'] = pd.to_datetime(trimmed_sales_df['SalesDate'])\n",
    "print(\" 'SalesDate' column in trimmed_sales_df ensured as datetime format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8fd208",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Step 2: Merging with Product and Category Data & Recalculating TotalPrice ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606893ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only necessary columns from products_df before merging\n",
    "products_relevant_cols = ['ProductID', 'ProductName', 'Price', 'CategoryID']\n",
    "merged_df = pd.merge(trimmed_sales_df, products_df[products_relevant_cols], on='ProductID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d463afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with categories_df on CategoryID to get CategoryName\n",
    "categories_relevant_cols = ['CategoryID', 'CategoryName']\n",
    "merged_df = pd.merge(merged_df, categories_df[categories_relevant_cols], on='CategoryID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9378dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Products and Categories data merged with trimmed sales data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f730366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate TotalPrice (important after merging with 'Price' from products_df)\n",
    "# This uses the 'Price' from products.csv which is assumed to be the base price\n",
    "merged_df['TotalPrice'] = merged_df['Quantity'] * merged_df['Price'] * (1 - merged_df['Discount'])\n",
    "print(\"TotalPrice recalculated using merged product prices.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1fff7a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# --- Feature Engineering (Time-based) ---\n",
    "# Re-extract time-based features as they might be needed for consistency or re-calculation\n",
    "merged_df['SaleYear'] = merged_df['SalesDate'].dt.year\n",
    "merged_df['SaleMonth'] = merged_df['SalesDate'].dt.month_name()\n",
    "merged_df['SaleWeekday'] = merged_df['SalesDate'].dt.day_name()\n",
    "merged_df['SaleWeek'] = merged_df['SalesDate'].dt.isocalendar().week.astype(int)\n",
    "print(\"Time-based features extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47af92b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Step 3: Filtering Products and Categories for Indian Grocery Store Relevance ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eea81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of product names to exclude that are not typically found in Indian grocery stores.\n",
    "products_to_exclude = [\n",
    "    'Barramundi', 'Creme De Banane - Marie', 'Shrimp - 31/40',\n",
    "    'Orange - Canned, Mandarin', 'Cheese - Boursin, Garlic / Herbs',\n",
    "    'Veal - Osso Bucco', 'Tomato - Tricolor Cherry', 'Grenadine',\n",
    "    'Salmon - Atlantic, Skin On', 'Coffee - Irish Cream',\n",
    "    'Crab - Dungeness, Whole', 'Sole - Dover, Whole, Fresh',\n",
    "    'Sauce - Demi Glace', 'Seedlings - Mix, Organic',\n",
    "    'Vanilla Beans', 'Bread Crumbs - Japanese Style'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf952378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of categories to explicitly include as per your request\n",
    "categories_to_include = [\n",
    "    'Confections',\n",
    "    'Produce',\n",
    "    'Beverages',\n",
    "    'Grain'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbab42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filters sequentially\n",
    "# Filter out products not typically found in Indian grocery stores\n",
    "filtered_by_product_exclusion = merged_df[~merged_df['ProductName'].isin(products_to_exclude)].copy()\n",
    "print(f\"Filtered by product exclusion. Rows remaining: {len(filtered_by_product_exclusion)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9db4d4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Further filter by the specified categories\n",
    "final_preprocessed_df = filtered_by_product_exclusion[\n",
    "    filtered_by_product_exclusion['CategoryName'].isin(categories_to_include)\n",
    "].copy()\n",
    "print(f\"Further filtered by category inclusion ({categories_to_include}). Final rows: {len(final_preprocessed_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f6ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Step 4: Remove Unnecessary Columns from the final filtered DataFrame ---\")\n",
    "# Only keep columns that are useful for the analysis (Sales Trend, Forecasting, Inventory Turnover, ABC Analysis)\n",
    "columns_to_keep = [\n",
    "    'ProductID', 'ProductName', 'CategoryID', 'CategoryName', 'Quantity', 'Discount', 'TotalPrice', 'SalesDate',\n",
    "    'SaleYear', 'SaleMonth', 'SaleWeekday', 'SaleWeek', 'Price' # 'Price' is retained for COGS calculation in Inventory Turnover\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d379465",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preprocessed_df = final_preprocessed_df[columns_to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0e78fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Data Preprocessing Complete ---\")\n",
    "print(\"Final preprocessed DataFrame (final_preprocessed_df) ready for analysis.\")\n",
    "print(\"\\nFirst 5 rows of final_preprocessed_df:\")\n",
    "print(final_preprocessed_df.head())\n",
    "print(\"\\nInformation about final_preprocessed_df:\")\n",
    "print(final_preprocessed_df.info())"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
